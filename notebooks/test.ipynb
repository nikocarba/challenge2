{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33d4520a-a3a6-4fca-870e-db937a3be470",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.5.0\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, count\n",
    "import pyspark\n",
    "\n",
    "print(pyspark.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d3438a7-7cc6-46e5-89fb-fe10406ba80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Spark session\n",
    "spark = SparkSession.builder.appName(\"GroupCSVData\").getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ddc2f48a-7005-4d4c-ba00-a3a75dc792f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+-------+---+--------+------+---------+--------------+\n",
      "|hour|calls|seconds|sms|    date|region|id_source|id_destination|\n",
      "+----+-----+-------+---+--------+------+---------+--------------+\n",
      "|  11|    1|     24|  0|20211001|     5|      BF3|           374|\n",
      "|   1|    1|     51|  0|20211001|     4|      9F5|           374|\n",
      "|  11|    1|      3|  0|20211001|     6|      025|           374|\n",
      "|  10|    1|     36|  0|20211001|     5|      FB6|           D52|\n",
      "|  23|    4|    137|  0|20211001|     8|      4BB|           861|\n",
      "|  18|    0|      0|  1|20211001|     4|      90C|           5B0|\n",
      "|  13|    1|    618|  0|20211001|     9|      7AB|           4CA|\n",
      "|  16|    1|    172|  0|20211001|     9|      7AB|           4CA|\n",
      "|   6|    1|    208|  0|20211001|     9|      7AB|           4CA|\n",
      "|   5|    1|     66|  0|20211001|     9|      7AB|           4CA|\n",
      "|  18|    1|    135|  0|20211001|     9|      7AB|           4CA|\n",
      "|  12|    0|      0|  8|20211001|     9|      0A4|           465|\n",
      "|  21|    1|      6|  0|20211001|     7|      2DF|           048|\n",
      "|  15|    1|     26|  0|20211001|     9|      3C0|           048|\n",
      "|  20|    1|      5|  0|20211001|     5|      DF9|           D5B|\n",
      "|   8|    1|    122|  0|20211001|     5|      DF9|           D5B|\n",
      "|  15|    2|    336|  0|20211001|     5|      DF9|           D5B|\n",
      "|   9|    1|      3|  0|20211001|     8|      04C|           FD6|\n",
      "|  13|    2|     12|  0|20211001|     2|      4CC|           FD6|\n",
      "|  18|    1|   1299|  0|20211001|     9|      250|          NULL|\n",
      "+----+-----+-------+---+--------+------+---------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Path to the CSV file\n",
    "csv_file_path = \"../data/events.csv.gz\"\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "df_eventos = spark.read.csv(csv_file_path, header=True, inferSchema=True)\n",
    "\n",
    "# Show the first few rows of the DataFrame\n",
    "df_eventos.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "26d690a8-b4ba-41c9-8df8-32615bf9aadc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- hour: integer (nullable = true)\n",
      " |-- calls: integer (nullable = true)\n",
      " |-- seconds: integer (nullable = true)\n",
      " |-- sms: integer (nullable = true)\n",
      " |-- date: integer (nullable = true)\n",
      " |-- region: integer (nullable = true)\n",
      " |-- id_source: string (nullable = true)\n",
      " |-- id_destination: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Mostrar el esquema del DataFrame\n",
    "df_eventos.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f196e2a8-d76a-4011-b995-79dfc6f34428",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_eventos.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c33c9c74-8f5b-4220-a6bb-f9192f986c00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+-------+---+----+------+---------+--------------+\n",
      "|hour|calls|seconds|sms|date|region|id_source|id_destination|\n",
      "+----+-----+-------+---+----+------+---------+--------------+\n",
      "|   0|    0|      0|  0|   0|     0|       18|            15|\n",
      "+----+-----+-------+---+----+------+---------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, sum\n",
    "\n",
    "nulos_por_columna = df_eventos.select([sum(col(c).isNull().cast(\"int\")).alias(c) for c in df_eventos.columns])\n",
    "nulos_por_columna.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "898bddad-db98-4e71-a656-146eb8b58e81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "999970"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Eliminar registros con nulos en \"id_source\" y \"id_destination\"\n",
    "df_eventos = df_eventos.dropna(subset=[\"id_source\", \"id_destination\"])\n",
    "df_eventos.count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fbe7e6ec-7656-45e4-86ad-a462b7bd3731",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n",
      "| id|\n",
      "+---+\n",
      "|374|\n",
      "|D52|\n",
      "|861|\n",
      "|5B0|\n",
      "|4CA|\n",
      "|465|\n",
      "|048|\n",
      "|D5B|\n",
      "|FD6|\n",
      "|2D3|\n",
      "|B3F|\n",
      "|6AF|\n",
      "|216|\n",
      "|C3A|\n",
      "|EE2|\n",
      "|328|\n",
      "|99E|\n",
      "|BF6|\n",
      "|60F|\n",
      "|6AC|\n",
      "+---+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Path to the CSV file\n",
    "csv_file_path = \"../data/free_sms_destinations.csv.gz\"\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "df_free_ids = spark.read.csv(csv_file_path, header=True, inferSchema=True)\n",
    "\n",
    "# Show the first few rows of the DataFrame\n",
    "df_free_ids.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d12d67f7-61bb-4b2c-aae9-88f1c9c7d723",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+-------+---+--------+------+---------+--------------+----+\n",
      "|hour|calls|seconds|sms|    date|region|id_source|id_destination|  id|\n",
      "+----+-----+-------+---+--------+------+---------+--------------+----+\n",
      "|   8|    1|    189|  0|20211001|     7|      395|           A7C|NULL|\n",
      "|   9|    1|    636|  0|20211001|     7|      D61|           A7C|NULL|\n",
      "|  19|    1|    751|  0|20211001|     7|      8C1|           A7C|NULL|\n",
      "|  17|    1|   6386|  0|20211001|     7|      316|           A7C|NULL|\n",
      "|  20|    1|   6504|  0|20211001|     7|      BDB|           A7C|NULL|\n",
      "|  20|    1|   1972|  0|20211001|     7|      CC7|           A7C|NULL|\n",
      "|  18|    1|     81|  0|20211001|     7|      3F6|           0CC|NULL|\n",
      "|   9|    1|     18|  0|20211001|     7|      88F|           260|NULL|\n",
      "|  17|    2|     51|  0|20211001|     5|      80A|           260|NULL|\n",
      "|  10|    1|     87|  0|20211001|     7|      FFD|           260|NULL|\n",
      "|  18|    1|     19|  0|20211001|     7|      DF4|           260|NULL|\n",
      "|  20|    0|      0|  1|20211001|     7|      6BD|           260|NULL|\n",
      "|   8|    1|     48|  0|20211001|     7|      BA9|           27C|NULL|\n",
      "|   9|    1|     14|  0|20211001|     7|      BA9|           27C|NULL|\n",
      "|  19|    1|   1292|  0|20211001|     7|      942|           AB7|NULL|\n",
      "|  18|    4|   1613|  0|20211001|     7|      72F|           DB6|NULL|\n",
      "|  17|    2|   6772|  0|20211001|     7|      72F|           DB6|NULL|\n",
      "|  14|    1|    103|  0|20211001|     7|      F7A|           339|NULL|\n",
      "|  16|    1|     17|  0|20211001|     7|      F7A|           339|NULL|\n",
      "|  11|    1|    132|  0|20211001|     7|      F7A|           339|NULL|\n",
      "+----+-----+-------+---+--------+------+---------+--------------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Left join en la columna \"id_destination\"\n",
    "joined_df = df_eventos.join(df_free_ids, df_eventos[\"id_destination\"] == df_free_ids[\"id\"], how=\"left\")\n",
    "joined_df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b511a194-96ef-422d-8c8e-5628ecc6c8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_facturacion = joined_df.groupBy(\"id_source\").agg(count(\"*\").alias(\"count\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
